---
layout: post
comments: true
title:  "Tổng quan về Natural Language Preprocessing (NLP)"
title2:  "1. Tổng quan về Natural Language Preprocessing (NLP)"
date:   2017-11-23 15:22:00
permalink: 2017/11/23/nlp/
mathjax: true
tags: NLP
category: NLP
sc_project: 11281831
sc_security: f2dfc7eb
img: \assets\NLP_intro\NLP_intro.png
summary: Tổng quan về Natural Language Preprocessing (NLP)
---
*Note: trong blog này tôi vẫn sẽ giữ nguyên các thuật ngữ chuyên ngành tiếng anh (bên cạnh có dịch sơ lược sang tiếng việt). Tôi cũng khuyến khích bạn đọc nên sử dụng các thuật ngữ này khi nói hay làm việc, để có sự thống nhất đồng bộ và tránh những nhầm lẫn không đáng có. Ví dụ: bạn thường nên dùng thuật ngữ "Machine Learning" hơn là sử dụng "máy học"*

**Natural Language Preprocessing (NLP)** (dịch sang tiếng việt là **"Xử lý ngôn ngữ tự nhiên"**) là một mảng đang nhận được rất nhiều sự chú ý trong giới khoa học về Machine Learning (Máy học) gần đây, đặc biệt là từ năm 2012 với sự ra đời của **word2vec**.  

### Ứng dụng của NLP trong thực tế:

### Các thuật ngữ cơ bản:
1. Đầu tiên chúng ta sẽ cùng làm quen với 1 thuật ngữ cơ bản nhất trong NLP là **word embedding** (tạm dịch ra là **nhúng từ**): Đây là kỹ thuật biến đổi *1 từ* hay *câu* có trong *từ điển* sang dạng *vectors số*.    
Hiểu đơn giản là ngôn ngữ bình thường con người sử dụng là dạng *từ* hay *câu* trong khi ngôn ngữ của máy tính là dạng *số*. Vậy thì để máy tính có thể hiểu được ngôn ngữ con người, cần 1 cách thức có thể chuyển ngôn ngữ người sang ngôn ngữ máy và ngược lại. Trong toán học, **embedding** ( dịch là **nhúng**) dùng để chỉ 1 hàm hay 1 cách biến đổi 1 tập hợp X sang tập hợp Y -- hay ta gọi nhúng X vào Y.

2. **Word vectors** (**word embeddings** or **distributed representations**):


### Lịch sử của word embeddings




This post is credited to the course: [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)
